{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6d598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=os.environ.get(\"MODEL_NAME\"),\n",
    "    temperature=0,\n",
    "    base_url=os.environ.get(\"COMPATIBLE_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"COMPATIBLE_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad69ad23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='â€œç¦»ç¦»åŸä¸Šè‰â€çš„ä¸‹ä¸€å¥æ˜¯ï¼šâ€œä¸€å²ä¸€æ¯è£ã€‚â€\\n\\nè¿™å¥è¯—å‡ºè‡ªå”ä»£è¯—äººç™½å±…æ˜“çš„ã€Šèµ‹å¾—å¤åŸè‰é€åˆ«ã€‹ã€‚å…¨è¯—å¦‚ä¸‹ï¼š\\n\\n> ç¦»ç¦»åŸä¸Šè‰ï¼Œä¸€å²ä¸€æ¯è£ã€‚  \\n> é‡ç«çƒ§ä¸å°½ï¼Œæ˜¥é£å¹åˆç”Ÿã€‚  \\n> è¿œèŠ³ä¾µå¤é“ï¼Œæ™´ç¿ æ¥è’åŸã€‚  \\n> åˆé€ç‹å­™å»ï¼Œè‹è‹æ»¡åˆ«æƒ…ã€‚\\n\\nå…¶ä¸­ï¼Œâ€œç¦»ç¦»â€å½¢å®¹è‰æœ¨èŒ‚ç››çš„æ ·å­ï¼Œâ€œä¸€å²ä¸€æ¯è£â€æ„ä¸ºé‡è‰æ¯å¹´ç»å†ä¸€æ¬¡æ¯èä¸ç¹èŒ‚çš„å¾ªç¯ï¼Œå±•ç°äº†è‡ªç„¶ç•Œçš„ç”Ÿç”Ÿä¸æ¯ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 17, 'total_tokens': 155, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-7de7a23a-2ef5-4787-89c8-e872de7bba1f', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b35f72ea-c97f-47a8-8baf-df156fc3173a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 138, 'total_tokens': 155, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"ç¦»ç¦»åŸä¸Šè‰çš„ä¸‹ä¸€å¥ã€‚\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fddef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='å†™ä¸€ä¸ª REST API çš„æ­¥éª¤ä¼šæ ¹æ®ä½ ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶æœ‰æ‰€ä¸åŒï¼Œä½†æ ¸å¿ƒåŸåˆ™æ˜¯ä¸€è‡´çš„ã€‚ä¸‹é¢æˆ‘ä¼šä»¥ **Python + Flask** ä¸ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å¿«é€Ÿæ­å»ºä¸€ä¸ªç®€å•çš„ REST APIã€‚\\n\\n---\\n\\n## ğŸ§± ä¸€ã€REST API åŸºç¡€æ¦‚å¿µ\\n\\nRESTï¼ˆRepresentational State Transferï¼‰æ˜¯ä¸€ç§è®¾è®¡é£æ ¼ï¼Œé€šå¸¸ä½¿ç”¨ HTTP æ–¹æ³•æ¥æ“ä½œèµ„æºï¼š\\n\\n- `GET`ï¼šè·å–èµ„æº\\n- `POST`ï¼šåˆ›å»ºèµ„æº\\n- `PUT` / `PATCH`ï¼šæ›´æ–°èµ„æº\\n- `DELETE`ï¼šåˆ é™¤èµ„æº\\n\\n---\\n\\n## ğŸ äºŒã€ç”¨ Python Flask å†™ä¸€ä¸ªç®€å• REST API\\n\\n### 1. å®‰è£… Flask\\n\\n```bash\\npip install flask\\n```\\n\\n### 2. ç¼–å†™ä»£ç ï¼ˆä¾‹å¦‚ï¼šç®¡ç†ç”¨æˆ·ï¼‰\\n\\n```python\\nfrom flask import Flask, jsonify, request\\n\\napp = Flask(__name__)\\n\\n# æ¨¡æ‹Ÿæ•°æ®åº“ï¼ˆå®é™…é¡¹ç›®ä¸­åº”ä½¿ç”¨æ•°æ®åº“å¦‚ SQLiteã€PostgreSQL ç­‰ï¼‰\\nusers = [\\n    {\"id\": 1, \"name\": \"Alice\"},\\n    {\"id\": 2, \"name\": \"Bob\"}\\n]\\n\\n# GET /users - è·å–æ‰€æœ‰ç”¨æˆ·\\n@app.route(\\'/users\\', methods=[\\'GET\\'])\\ndef get_users():\\n    return jsonify(users)\\n\\n# GET /users/<id> - è·å–å•ä¸ªç”¨æˆ·\\n@app.route(\\'/users/<int:user_id>\\', methods=[\\'GET\\'])\\ndef get_user(user_id):\\n    user = next((u for u in users if u[\"id\"] == user_id), None)\\n    if user:\\n        return jsonify(user)\\n    else:\\n        return jsonify({\"error\": \"User not found\"}), 404\\n\\n# POST /users - åˆ›å»ºæ–°ç”¨æˆ·\\n@app.route(\\'/users\\', methods=[\\'POST\\'])\\ndef create_user():\\n    data = request.get_json()\\n    new_id = max(u[\"id\"] for u in users) + 1 if users else 1\\n    new_user = {\"id\": new_id, \"name\": data[\"name\"]}\\n    users.append(new_user)\\n    return jsonify(new_user), 201\\n\\n# PUT /users/<id> - æ›´æ–°ç”¨æˆ·\\n@app.route(\\'/users/<int:user_id>\\', methods=[\\'PUT\\'])\\ndef update_user(user_id):\\n    user = next((u for u in users if u[\"id\"] == user_id), None)\\n    if not user:\\n        return jsonify({\"error\": \"User not found\"}), 404\\n    data = request.get_json()\\n    user[\"name\"] = data[\"name\"]\\n    return jsonify(user)\\n\\n# DELETE /users/<id> - åˆ é™¤ç”¨æˆ·\\n@app.route(\\'/users/<int:user_id>\\', methods=[\\'DELETE\\'])\\ndef delete_user(user_id):\\n    global users\\n    users = [u for u in users if u[\"id\"] != user_id]\\n    return \\'\\', 204  # No Content\\n\\nif __name__ == \\'__main__\\':\\n    app.run(debug=True)\\n```\\n\\n### 3. è¿è¡ŒæœåŠ¡\\n\\n```bash\\npython app.py\\n```\\n\\né»˜è®¤ä¼šåœ¨ `http://localhost:5000` å¯åŠ¨ã€‚\\n\\n---\\n\\n## ğŸ§ª ä¸‰ã€æµ‹è¯• APIï¼ˆå¯ä»¥ç”¨ curl æˆ– Postmanï¼‰\\n\\n```bash\\n# è·å–æ‰€æœ‰ç”¨æˆ·\\ncurl http://localhost:5000/users\\n\\n# åˆ›å»ºç”¨æˆ·\\ncurl -X POST -H \"Content-Type: application/json\" \\\\\\n     -d \\'{\"name\":\"Charlie\"}\\' http://localhost:5000/users\\n\\n# è·å– ID ä¸º 1 çš„ç”¨æˆ·\\ncurl http://localhost:5000/users/1\\n\\n# æ›´æ–°ç”¨æˆ·\\ncurl -X PUT -H \"Content-Type: application/json\" \\\\\\n     -d \\'{\"name\":\"Alice Updated\"}\\' http://localhost:5000/users/1\\n\\n# åˆ é™¤ç”¨æˆ·\\ncurl -X DELETE http://localhost:5000/users/1\\n```\\n\\n---\\n\\n## ğŸ›  å››ã€è¿›é˜¶å»ºè®®\\n\\n- ä½¿ç”¨ **Flask-RESTful** æˆ– **FastAPI**ï¼ˆæ›´ç°ä»£ã€è‡ªåŠ¨æ–‡æ¡£ï¼‰ç®€åŒ–å¼€å‘ã€‚\\n- æ·»åŠ  **è¾“å…¥éªŒè¯**ï¼ˆå¦‚ä½¿ç”¨ Pydanticï¼‰ã€‚\\n- è¿æ¥çœŸå®æ•°æ®åº“ï¼ˆå¦‚ SQLAlchemy + SQLite/PostgreSQLï¼‰ã€‚\\n- æ·»åŠ  **èº«ä»½è®¤è¯**ï¼ˆJWTã€OAuthï¼‰ã€‚\\n- ä½¿ç”¨ **Swagger/OpenAPI** è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£ï¼ˆFastAPI è‡ªå¸¦ï¼‰ã€‚\\n\\n---\\n\\n## âœ… ç¤ºä¾‹ï¼šç”¨ FastAPIï¼ˆæ¨èç”¨äºæ–°é¡¹ç›®ï¼‰\\n\\n```python\\nfrom fastapi import FastAPI\\n\\napp = FastAPI()\\n\\nusers = [{\"id\": 1, \"name\": \"Alice\"}]\\n\\n@app.get(\"/users\")\\ndef get_users():\\n    return users\\n\\n@app.post(\"/users\")\\ndef create_user(name: str):\\n    new_id = max(u[\"id\"] for u in users) + 1\\n    users.append({\"id\": new_id, \"name\": name})\\n    return {\"id\": new_id, \"name\": name}\\n```\\n\\nè¿è¡Œåè®¿é—® `http://localhost:8000/docs` å³å¯çœ‹åˆ°äº¤äº’å¼æ–‡æ¡£ï¼\\n\\n---\\n\\nå¦‚æœä½ å‘Šè¯‰æˆ‘ä½ ç”¨çš„è¯­è¨€æˆ–æ¡†æ¶ï¼ˆå¦‚ Node.jsã€Java Springã€Goã€Django ç­‰ï¼‰ï¼Œæˆ‘å¯ä»¥æä¾›å¯¹åº”ç‰ˆæœ¬çš„ç¤ºä¾‹ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1062, 'prompt_tokens': 26, 'total_tokens': 1088, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-15d2ddb2-0c73-4287-b6e3-97ffdf16d84d', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--135c62ea-582e-48e4-b46d-435f93f81af5-0', usage_metadata={'input_tokens': 26, 'output_tokens': 1062, 'total_tokens': 1088, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"ä½ æ˜¯ä¸€ä¸ªç²¾é€šä»£ç çš„åŠ©æ‰‹ã€‚\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"æ€ä¹ˆå†™ä¸€ä¸ªREST APIï¼Ÿ\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306c1c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'Paris'},\n",
       "  'id': 'call_d7ba5a7dca52477ca6b62cd7',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "response = model_with_tools.invoke(\"What's the weather in Paris?\")\n",
    "\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfe411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content='Hello', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content='! How can', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content=' I help', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content=' you today?', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content=' ğŸ˜Š', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485'),\n",
       " AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-max', 'model_provider': 'openai'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485', chunk_position='last')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = []\n",
    "full_message = None\n",
    "for chunk in model.stream(\"Hi\"):\n",
    "    chunks.append(chunk)\n",
    "    full_message = chunk if full_message is None else full_message + chunk\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fd26cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Hello! How can I help you today? ğŸ˜Š', additional_kwargs={}, response_metadata={'model_provider': 'openai', 'finish_reason': 'stop', 'model_name': 'qwen3-max'}, id='lc_run--2a6e3789-1db9-417e-aa4a-d9987c6d9485', chunk_position='last')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "624b0536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The weather in San Francisco is currently sunny with a temperature of 72Â°F.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 60, 'total_tokens': 77, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-22b5d16c-4c32-4d3c-bbc2-5ac5feef0aed', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--59172e60-0c38-4b63-848f-d9b85398a62c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "# After a model makes a tool call\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",\n",
    "        \"args\": {\"location\": \"San Francisco\"},\n",
    "        \"id\": \"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Execute tool and create result message\n",
    "weather_result = \"Sunny, 72Â°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # Must match the call ID\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "messages = [\n",
    "    HumanMessage(\"What's the weather in San Francisco?\"),\n",
    "    ai_message,  # Model's tool call\n",
    "    tool_message,  # Tool execution result\n",
    "]\n",
    "model.invoke(messages)  # Model processes the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba651c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
