{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1781ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=os.environ.get(\"MODEL_NAME\"),\n",
    "    temperature=0,\n",
    "    base_url=os.environ.get(\"COMPATIBLE_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"COMPATIBLE_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5311a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bob.', additional_kwargs={}, response_metadata={}, id='4a555b38-5b3a-4933-881f-96e7a1bda10e'),\n",
       "  AIMessage(content='Hi Bob! Nice to meet you. How can I help you today? ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 15, 'total_tokens': 32, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-2c309198-8ec1-4b34-b97d-bb6017d3d90c', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2d8f5627-e7b9-4247-8103-fee32cd17ad4-0', usage_metadata={'input_tokens': 15, 'output_tokens': 17, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    checkpointer=InMemorySaver(),  \n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"Hi! My name is Bob.\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8932b8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi! My name is Bob.', additional_kwargs={}, response_metadata={}, id='4a555b38-5b3a-4933-881f-96e7a1bda10e'),\n",
       "  AIMessage(content='Hi Bob! Nice to meet you. How can I help you today? ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 15, 'total_tokens': 32, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-2c309198-8ec1-4b34-b97d-bb6017d3d90c', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2d8f5627-e7b9-4247-8103-fee32cd17ad4-0', usage_metadata={'input_tokens': 15, 'output_tokens': 17, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='eecc5a74-1871-4b66-9010-303a50aeec33'),\n",
       "  AIMessage(content='Your name is Bob! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 47, 'total_tokens': 54, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-0f3d95f6-defe-4137-8c65-fdde9fd05f47', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b9df0c9e-255b-4259-8f58-c8871ab5eee5-0', usage_metadata={'input_tokens': 47, 'output_tokens': 7, 'total_tokens': 54, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"What's my name?\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36b885f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='a4959c34-632f-43b8-886b-f9d56771dd77'),\n",
       "  AIMessage(content='I donâ€™t know your name! You havenâ€™t told me yet. ðŸ˜Š  \\nFeel free to share it if youâ€™d likeâ€”Iâ€™d be happy to use it!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 13, 'total_tokens': 47, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-3793e603-bad5-4a5c-b772-28e3846064d1', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--193bb868-b5a0-4a16-bffc-9bf421a170e8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 34, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": [HumanMessage(\"What's my name?\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2d8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[],\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": HumanMessage(\"hi, my name is bob\")}, config)\n",
    "agent.invoke({\"messages\": HumanMessage(\"write a short poem about cats\")}, config)\n",
    "agent.invoke({\"messages\": HumanMessage(\"now do the same but for dogs\")}, config)\n",
    "final_response = agent.invoke({\"messages\": HumanMessage(\"what's my name?\")}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f967ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi, my name is bob', additional_kwargs={}, response_metadata={}, id='2da7f4e7-7922-4826-b6b1-31418c3a50b0'),\n",
       " AIMessage(content=\"Here's a short poem for you, Bob:\\n\\n**Purr-fect Companions**\\n\\nSoft paws on the sill,  \\nEyes like moonlight, calm and still.  \\nA flick of the tail, a gentle sighâ€”  \\nWatching clouds drift slowly by.  \\n\\nThen *pounce!* A toy, a sunbeam bright,  \\nA blur of fur in playful flight.  \\nBut when the day is done, youâ€™ll see  \\nThem curled up close, purring near me.  \\n\\nâ€” For Bob, who appreciates cats! ðŸ˜º\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 47, 'total_tokens': 159, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-0637c5ad-0939-4aa9-a97d-78d01b93b795', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--efbfba16-685b-496c-a42d-24c574187ee1-0', usage_metadata={'input_tokens': 47, 'output_tokens': 112, 'total_tokens': 159, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       " HumanMessage(content='now do the same but for dogs', additional_kwargs={}, response_metadata={}, id='6aa3b4d7-5510-403b-9e93-c313a3131bf0'),\n",
       " AIMessage(content=\"Of course, Bob! Here's a short poem about dogs:\\n\\n**Faithful Friends**\\n\\nWagging tail and eager eyes,  \\nReady for adventuresâ€”big or small surprises.  \\nMuddy paws and joyful bark,  \\nChasing squirrels through morning park.  \\n\\nLoyal heart that never strays,  \\nBeaming love in countless ways.  \\nWhen the world feels cold or gray,  \\nThey greet you like itâ€™s Christmas Day.  \\n\\nâ€” For Bob, with a dogâ€™s warm hello! ðŸ¾\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 176, 'total_tokens': 282, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-4ccbcfcb-5bd9-4e35-bd1f-d84e18c73e52', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--30aad53b-6a68-4f3b-8cef-46262c5658eb-0', usage_metadata={'input_tokens': 176, 'output_tokens': 106, 'total_tokens': 282, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='942d26a7-8118-4027-b4eb-033476f9f171'),\n",
       " AIMessage(content='Your name is Bob! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 264, 'total_tokens': 271, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'qwen3-max', 'system_fingerprint': None, 'id': 'chatcmpl-4ea10053-cf00-4476-8cd9-996bf07968fd', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e0456f3d-07ef-474f-95f0-a4db7f27d241-0', usage_metadata={'input_tokens': 264, 'output_tokens': 7, 'total_tokens': 271, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3091dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', \"hi! I'm bob\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.middleware import after_model\n",
    "\n",
    "\n",
    "@after_model\n",
    "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
    "    \"\"\"Remove old messages to keep conversation manageable.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 2:\n",
    "        # remove the earliest two messages\n",
    "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
    "    return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    system_prompt=\"Please be concise and to the point.\",\n",
    "    middleware=[delete_old_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [HumanMessage(\"hi! I'm bob\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da478198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?'), ('human', \"what's my name?\")]\n",
      "[('human', \"hi! I'm bob\"), ('ai', 'Hi Bob! How can I help you today?'), ('human', \"what's my name?\"), ('ai', 'Your name is Bob!')]\n",
      "[('human', \"what's my name?\"), ('ai', 'Your name is Bob!')]\n"
     ]
    }
   ],
   "source": [
    "for event in agent.stream(\n",
    "    {\"messages\": [HumanMessage(\"what's my name?\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print([(message.type, message.content) for message in event[\"messages\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=model,\n",
    "            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens\n",
    "            messages_to_keep=20,  # Keep last 20 messages after summary\n",
    "        )\n",
    "    ],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba439c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
